{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95955c77-71ea-43cb-b7f7-7f3176313762",
   "metadata": {
    "tags": []
   },
   "source": [
    "batchsize = 256\n",
    "512 : 96.85\n",
    "256 : 98.2\n",
    "128 : 98.15\n",
    "64 : 97.95\n",
    "32 : 98.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280c992a-7740-4243-905e-f62ea1d2234a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361eec62-ac69-43e5-bfe2-55284afe7502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "config = {\n",
    "  \"data\": {\n",
    "    \"high_dim_path\": 'data/MRI_0328.csv',\n",
    "    \"low_dim_path\": 'data/ALL.csv',\n",
    "    \"labels_path\": 'data/LABEL.csv',\n",
    "    \"brain_region_adjacency_path\" : 'data/region_adjacency.csv',\n",
    "    \"batch_size\": 64,\n",
    "    \"shuffle\": False,\n",
    "    \"test_size\":0.01,\n",
    "    \"val_size\":0.2,\n",
    "    \"random_state\":12345\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"type\": \"Graph_based_MLP\", # 设置模型跑哪个\n",
    "    \"way_adjmatrix\" : \"apoe\", # 邻接矩阵如何构造\n",
    "    \"high_dim_input_size\": 498 ,  \n",
    "    \"low_dim_input_size\":17,\n",
    "    \"embedding_dim\":128,\n",
    "    \"output_dim\":2,\n",
    "    \"hidden_channels\":128,\n",
    "    \"num_heads\":4 ,\n",
    "    \"num_features\":3 # 每个脑区的特征数\n",
    "      \n",
    "  },\n",
    "  \"train\": {\n",
    "    \"repeat_times\" :10, # 简单完成交叉验证的任务\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"device\": \"cuda:1\"\n",
    "  },\n",
    "  \"earlystopping\":{\n",
    "    \"is_on\":False,\n",
    "    \"patience\":5,\n",
    "    \"delta\":0.01\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60bfbaed-866e-460e-acd2-97fea58bff91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共分割样本10次，随机数种子为：[6618, 6238, 3278, 9821, 2929, 3772, 4070, 2183, 1418, 4114]\n",
      "Model:Graph_based_MLP\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 101\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraph_based_MLP\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mGraph_based_MLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhigh_dim_input_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhigh_dim_input_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 适当调整这些参数，这里可以写成config\u001b[39;49;00m\n\u001b[1;32m     97\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlow_dim_input_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlow_dim_input_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                 \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 根据您的任务调整\u001b[39;49;00m\n\u001b[1;32m    100\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mhidden_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhidden_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 101\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_high_correlation\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/myconda/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 集成版本\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import json\n",
    "from data.data_loader import load_and_align_data, create_data_loader\n",
    "from models.model import *\n",
    "from utils import *  # 假设你有评估和早停的辅助函数\n",
    "from torch_geometric.data import Data          \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "#from config import config\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 设置训练设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# 结果的接收器\n",
    "random.seed(99)\n",
    "result = []\n",
    "repeat_times = config['train']['repeat_times']\n",
    "random_state = config['data']['random_state']\n",
    "\n",
    "if repeat_times != 1:\n",
    "    random_state = [random.randint(0, 10000) for _ in range(config['train']['repeat_times'])]\n",
    "    print(f'共分割样本{repeat_times}次，随机数种子为：{random_state}')\n",
    "elif repeat_times == 1:\n",
    "    random_state = [config['data']['random_state']]\n",
    "    print(f'仅进行{repeat_times}次分割样本，随机数种子为：{random_state}')\n",
    "    \n",
    "brain_adj_matrix = read_brain_region_adjacency(config[\"data\"][\"brain_region_adjacency_path\"])\n",
    "brain_edge_index,_ = dense_to_sparse(brain_adj_matrix)\n",
    "\n",
    "for seed in random_state:\n",
    "    # 加载数据并创建数据集\n",
    "    train_dataset, val_dataset, _ = load_and_align_data(high_dim_path = config['data']['high_dim_path'], \n",
    "                                                      low_dim_path = config['data']['low_dim_path'],\n",
    "                                                      labels_path = config['data']['labels_path'],\n",
    "                                                      test_size = config['data']['test_size'],\n",
    "                                                      val_size = config['data']['val_size'],\n",
    "                                                      random_state = seed)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = create_data_loader(train_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    val_loader = create_data_loader(val_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    \n",
    "    if config['model']['type'] == 'CombinedGAT':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = CombinedGAT(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"],\n",
    "                     num_heads=config[\"model\"][\"num_heads\"]).to(device)\n",
    "    elif config['model']['type'] == 'Baseline_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Baseline_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'high_low_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = high_low_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'only_high_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = only_high_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'only_low_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = only_high_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'Only_high_GCN':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Only_high_GCN(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'Graph_based_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Graph_based_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"],\n",
    "                    num_features=config[\"model\"][\"num_features\"]).to(device)\n",
    "    elif config['model']['type'] == 'test_high_correlation':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = test_high_correlation(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'BrainGNN':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = BrainGNN(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"],\n",
    "                     num_features=config[\"model\"][\"num_features\"]\n",
    "                        ).to(device)\n",
    "    else:\n",
    "        print(f\"Not found Model:{config['model']['type']}\")\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['train']['learning_rate'])\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=5)\n",
    "    \n",
    "    # 初始化早停对象\n",
    "    early_stopping = EarlyStopping(patience=config[\"earlystopping\"][\"patience\"], delta=config[\"earlystopping\"][\"delta\"])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config['train']['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for high_dim_features, low_dim_features, labels in train_loader: \n",
    "            batch_size = high_dim_features.size(0)  # 获取当前批次的大小\n",
    "            \n",
    "            # 为当前批次生成全连接的邻接矩阵\n",
    "            if config[\"model\"][\"way_adjmatrix\"] == 'zero':\n",
    "                adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'only_three':\n",
    "                adj_matrix = build_adj_matrix_only_three(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'similarity_add_three':\n",
    "                adj_matrix = build_adj_matrix_similarity_add_three(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'sex':\n",
    "                adj_matrix = build_adj_matrix_sex(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'apoe':\n",
    "                adj_matrix = build_adj_matrix_apoe(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'mmse':\n",
    "                adj_matrix = build_adj_matrix_mmse(high_dim_features,low_dim_features,sigma=1)\n",
    "            edge_index, _ = dense_to_sparse(adj_matrix)\n",
    "            \n",
    "            # 准备数据\n",
    "            high_dim_features = high_dim_features.to(device)\n",
    "            low_dim_features = low_dim_features.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            high_dim_cov_matrix = cov_builder(high_dim_features , labels).to(device)\n",
    "\n",
    "            brain_edge_index = brain_edge_index.to(device)\n",
    "    \n",
    "            # 前向传播\n",
    "            outputs = model(high_dim_features, low_dim_features, brain_edge_index)#, high_dim_cov_matrix) #edge_index, high_dim_cov_matrix)\n",
    "            # outputs = model(high_dim_features, low_dim_features, edge_index, high_dim_cov_matrix)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "    \n",
    "        # 计算验证集上的损失\n",
    "        model.eval()\n",
    "        val_total_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_acc_list = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for high_dim_features, low_dim_features, labels in val_loader: \n",
    "                batch_size = high_dim_features.size(0)  # 获取当前批次的大小\n",
    "                \n",
    "                # 为当前批次生成全连接的邻接矩阵\n",
    "                if config[\"model\"][\"way_adjmatrix\"] == 'zero':\n",
    "                    adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'only_three':\n",
    "                    adj_matrix = build_adj_matrix_only_three(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'similarity_add_three':\n",
    "                    adj_matrix = build_adj_matrix_similarity_add_three(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'sex':\n",
    "                    adj_matrix = build_adj_matrix_sex(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'apoe':\n",
    "                    adj_matrix = build_adj_matrix_apoe(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'mmse':\n",
    "                    adj_matrix = build_adj_matrix_mmse(high_dim_features,low_dim_features,sigma=1)\n",
    "                edge_index, _ = dense_to_sparse(adj_matrix)\n",
    "                    \n",
    "                high_dim_features = high_dim_features.to(device)\n",
    "                low_dim_features = low_dim_features.float().to(device)\n",
    "                labels = labels.to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                \n",
    "                high_dim_cov_matrix = cov_builder(high_dim_features , labels).to(device)\n",
    "                \n",
    "                outputs = model(high_dim_features, low_dim_features, brain_edge_index)#,high_dim_cov_matrix)\n",
    "                #outputs = model(high_dim_features, low_dim_features, edge_index,high_dim_cov_matrix)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        val_loss =  val_total_loss/len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        scheduler.step(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.6f}, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.6f}')\n",
    "        # print(f'Wrong_sample:{val_total-val_correct},Index:{[index for index, (item1, item2) in enumerate(zip(predicted, labels)) if item1 != item2]}')\n",
    "        # print(predicted)\n",
    "        \n",
    "        if config[\"earlystopping\"][\"is_on\"]:\n",
    "            early_stopping(val_loss,model)\n",
    "            if  early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    predicted_list = predicted_list + predicted.tolist()\n",
    "    labels_list = labels_list + labels.tolist()\n",
    "                \n",
    "    result.append(max(val_acc_list))\n",
    "print(f'Finished! \\n Acc:{np.mean(result),max(result)}, \\n list:{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de764376-ebee-49e0-9b15-f53514de9345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8985"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_list) #2000\n",
    "predicted_list.count(0)\n",
    "predicted_list.count(1)\n",
    "labels_list.count(0)\n",
    "sum([1 for label, predicted in zip(labels_list, predicted_list) if label == predicted])/len(predicted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b65c958-50d7-4ae1-a07a-13848a8fc937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 685.,   35.],\n",
       "        [ 168., 1112.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = torch.tensor(predicted_list)\n",
    "labels = torch.tensor(labels_list)\n",
    "\n",
    "# 确定类别总数\n",
    "num_classes = torch.max(torch.cat((predicted, labels))) + 1\n",
    "\n",
    "# 初始化混淆矩阵\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "# 填充混淆矩阵\n",
    "for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a753efe4-b56d-4261-ace3-8769f43466a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8985\n",
      "Precision per class: 0.9514\n",
      "Recall per class: 0.8030\n",
      "F1 Score per class: 0.8709\n"
     ]
    }
   ],
   "source": [
    "# 计算性能指标\n",
    "TP = int(confusion_matrix[0][0])\n",
    "FP = int(confusion_matrix[0][1])\n",
    "FN = int(confusion_matrix[1][0])\n",
    "TN = int(confusion_matrix[1][1])\n",
    "\n",
    "# 精确率 Precision\n",
    "precision = TP / (TP + FP)\n",
    "# 召回率 Recall\n",
    "recall = TP / (TP + FN)\n",
    "# F1分数\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# 计算总体准确率\n",
    "accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision per class: {precision:.4f}')\n",
    "print(f'Recall per class: {recall:.4f}')\n",
    "print(f'F1 Score per class: {F1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d52a0c-aee6-4e2b-9a06-4fb1fa97fa75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
