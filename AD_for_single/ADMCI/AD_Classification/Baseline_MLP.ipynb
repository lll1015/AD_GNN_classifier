{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95955c77-71ea-43cb-b7f7-7f3176313762",
   "metadata": {
    "tags": []
   },
   "source": [
    "batchsize = 256\n",
    "512 : 96.85\n",
    "256 : 98.2\n",
    "128 : 98.15\n",
    "64 : 97.95\n",
    "32 : 98.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280c992a-7740-4243-905e-f62ea1d2234a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361eec62-ac69-43e5-bfe2-55284afe7502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "config = {\n",
    "  \"data\": {\n",
    "    \"high_dim_path\": 'data/MRI_0328.csv',\n",
    "    \"low_dim_path\": 'data/ALL.csv',\n",
    "    \"labels_path\": 'data/LABEL.csv',\n",
    "    \"brain_region_adjacency_path\" : 'data/region_adjacency.csv',\n",
    "    \"batch_size\": 256,\n",
    "    \"shuffle\": False,\n",
    "    \"test_size\":0.01,\n",
    "    \"val_size\":0.2,\n",
    "    \"random_state\":12345\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"type\": \"Baseline_MLP\", # 设置模型跑哪个\n",
    "    \"way_adjmatrix\" : \"apoe\", # 邻接矩阵如何构造\n",
    "    \"high_dim_input_size\": 498 ,  \n",
    "    \"low_dim_input_size\":17,\n",
    "    \"embedding_dim\":128,\n",
    "    \"output_dim\":2,\n",
    "    \"hidden_channels\":128,\n",
    "    \"num_heads\":4 ,\n",
    "    \"num_features\":3 # 每个脑区的特征数\n",
    "      \n",
    "  },\n",
    "  \"train\": {\n",
    "    \"repeat_times\" :10, # 简单完成交叉验证的任务\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"device\": \"cuda:1\"\n",
    "  },\n",
    "  \"earlystopping\":{\n",
    "    \"is_on\":False,\n",
    "    \"patience\":5,\n",
    "    \"delta\":0.01\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bfbaed-866e-460e-acd2-97fea58bff91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共分割样本10次，随机数种子为：[6618, 6238, 3278, 9821, 2929, 3772, 4070, 2183, 1418, 4114]\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.603445, Train Acc: 67.058824, Val Loss: 1.959249, Val Acc: 57.031250\n",
      "Epoch 2, Train Loss: 0.211082, Train Acc: 90.588235, Val Loss: 0.784013, Val Acc: 67.187500\n",
      "Epoch 3, Train Loss: 0.164248, Train Acc: 92.745098, Val Loss: 0.205296, Val Acc: 92.187500\n",
      "Epoch 4, Train Loss: 0.155518, Train Acc: 94.117647, Val Loss: 0.169013, Val Acc: 93.750000\n",
      "Epoch 5, Train Loss: 0.118487, Train Acc: 95.098039, Val Loss: 0.207355, Val Acc: 92.187500\n",
      "Epoch 6, Train Loss: 0.096181, Train Acc: 96.274510, Val Loss: 0.271176, Val Acc: 85.937500\n",
      "Epoch 7, Train Loss: 0.088424, Train Acc: 96.666667, Val Loss: 0.230330, Val Acc: 89.062500\n",
      "Epoch 8, Train Loss: 0.075542, Train Acc: 97.254902, Val Loss: 0.161965, Val Acc: 94.531250\n",
      "Epoch 9, Train Loss: 0.063071, Train Acc: 97.647059, Val Loss: 0.134286, Val Acc: 92.968750\n",
      "Epoch 10, Train Loss: 0.058164, Train Acc: 98.039216, Val Loss: 0.139591, Val Acc: 92.968750\n",
      "Epoch 11, Train Loss: 0.053998, Train Acc: 98.431373, Val Loss: 0.152124, Val Acc: 92.968750\n",
      "Epoch 12, Train Loss: 0.046116, Train Acc: 98.235294, Val Loss: 0.164141, Val Acc: 92.187500\n",
      "Epoch 13, Train Loss: 0.038141, Train Acc: 98.627451, Val Loss: 0.174876, Val Acc: 92.968750\n",
      "Epoch 14, Train Loss: 0.031898, Train Acc: 99.411765, Val Loss: 0.181626, Val Acc: 92.968750\n",
      "Epoch 15, Train Loss: 0.027818, Train Acc: 99.411765, Val Loss: 0.190767, Val Acc: 92.968750\n",
      "Epoch 16, Train Loss: 0.024385, Train Acc: 99.411765, Val Loss: 0.199429, Val Acc: 90.625000\n",
      "Epoch 17, Train Loss: 0.022970, Train Acc: 99.607843, Val Loss: 0.209980, Val Acc: 90.625000\n",
      "Epoch 18, Train Loss: 0.021482, Train Acc: 99.803922, Val Loss: 0.221492, Val Acc: 91.406250\n",
      "Epoch 19, Train Loss: 0.020129, Train Acc: 100.000000, Val Loss: 0.232812, Val Acc: 89.843750\n",
      "Epoch 20, Train Loss: 0.018980, Train Acc: 100.000000, Val Loss: 0.242655, Val Acc: 89.843750\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.715294, Train Acc: 61.176471, Val Loss: 0.290209, Val Acc: 88.281250\n",
      "Epoch 2, Train Loss: 0.246508, Train Acc: 87.843137, Val Loss: 0.252903, Val Acc: 88.281250\n",
      "Epoch 3, Train Loss: 0.187285, Train Acc: 92.352941, Val Loss: 0.396546, Val Acc: 79.687500\n",
      "Epoch 4, Train Loss: 0.177523, Train Acc: 93.137255, Val Loss: 0.208339, Val Acc: 89.843750\n",
      "Epoch 5, Train Loss: 0.133592, Train Acc: 94.313725, Val Loss: 0.220339, Val Acc: 90.625000\n",
      "Epoch 6, Train Loss: 0.101864, Train Acc: 95.882353, Val Loss: 0.326434, Val Acc: 87.500000\n",
      "Epoch 7, Train Loss: 0.089789, Train Acc: 96.078431, Val Loss: 0.325673, Val Acc: 89.062500\n",
      "Epoch 8, Train Loss: 0.075290, Train Acc: 96.470588, Val Loss: 0.275295, Val Acc: 89.062500\n",
      "Epoch 9, Train Loss: 0.063621, Train Acc: 97.254902, Val Loss: 0.241746, Val Acc: 89.843750\n",
      "Epoch 10, Train Loss: 0.055604, Train Acc: 97.843137, Val Loss: 0.227249, Val Acc: 90.625000\n",
      "Epoch 11, Train Loss: 0.051092, Train Acc: 98.431373, Val Loss: 0.221887, Val Acc: 91.406250\n",
      "Epoch 12, Train Loss: 0.048834, Train Acc: 98.627451, Val Loss: 0.219158, Val Acc: 91.406250\n",
      "Epoch 13, Train Loss: 0.045754, Train Acc: 98.823529, Val Loss: 0.218896, Val Acc: 92.187500\n",
      "Epoch 14, Train Loss: 0.042417, Train Acc: 98.627451, Val Loss: 0.220245, Val Acc: 92.187500\n",
      "Epoch 15, Train Loss: 0.039316, Train Acc: 98.823529, Val Loss: 0.222046, Val Acc: 92.968750\n",
      "Epoch 16, Train Loss: 0.036808, Train Acc: 99.019608, Val Loss: 0.223774, Val Acc: 92.968750\n",
      "Epoch 17, Train Loss: 0.034996, Train Acc: 99.019608, Val Loss: 0.222871, Val Acc: 92.968750\n",
      "Epoch 18, Train Loss: 0.034417, Train Acc: 99.019608, Val Loss: 0.222380, Val Acc: 92.968750\n",
      "Epoch 19, Train Loss: 0.033830, Train Acc: 99.019608, Val Loss: 0.222012, Val Acc: 92.968750\n",
      "Epoch 20, Train Loss: 0.033233, Train Acc: 99.215686, Val Loss: 0.222120, Val Acc: 93.750000\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.597898, Train Acc: 66.078431, Val Loss: 1.477626, Val Acc: 60.156250\n",
      "Epoch 2, Train Loss: 0.239095, Train Acc: 89.215686, Val Loss: 0.630657, Val Acc: 71.875000\n",
      "Epoch 3, Train Loss: 0.178323, Train Acc: 91.568627, Val Loss: 0.252636, Val Acc: 89.062500\n",
      "Epoch 4, Train Loss: 0.151221, Train Acc: 93.725490, Val Loss: 0.208401, Val Acc: 88.281250\n",
      "Epoch 5, Train Loss: 0.114783, Train Acc: 96.078431, Val Loss: 0.224531, Val Acc: 90.625000\n",
      "Epoch 6, Train Loss: 0.095742, Train Acc: 96.470588, Val Loss: 0.264151, Val Acc: 89.062500\n",
      "Epoch 7, Train Loss: 0.088988, Train Acc: 96.862745, Val Loss: 0.242282, Val Acc: 91.406250\n",
      "Epoch 8, Train Loss: 0.079033, Train Acc: 97.450980, Val Loss: 0.203938, Val Acc: 90.625000\n",
      "Epoch 9, Train Loss: 0.068329, Train Acc: 98.039216, Val Loss: 0.189336, Val Acc: 92.968750\n",
      "Epoch 10, Train Loss: 0.061080, Train Acc: 97.647059, Val Loss: 0.197373, Val Acc: 92.968750\n",
      "Epoch 11, Train Loss: 0.054294, Train Acc: 98.039216, Val Loss: 0.209024, Val Acc: 92.187500\n",
      "Epoch 12, Train Loss: 0.045710, Train Acc: 98.627451, Val Loss: 0.216542, Val Acc: 92.968750\n",
      "Epoch 13, Train Loss: 0.037443, Train Acc: 98.823529, Val Loss: 0.223964, Val Acc: 92.968750\n",
      "Epoch 14, Train Loss: 0.031028, Train Acc: 99.411765, Val Loss: 0.231471, Val Acc: 92.968750\n",
      "Epoch 15, Train Loss: 0.026941, Train Acc: 99.803922, Val Loss: 0.238434, Val Acc: 92.968750\n",
      "Epoch 16, Train Loss: 0.024604, Train Acc: 100.000000, Val Loss: 0.242503, Val Acc: 92.968750\n",
      "Epoch 17, Train Loss: 0.023538, Train Acc: 100.000000, Val Loss: 0.246061, Val Acc: 92.968750\n",
      "Epoch 18, Train Loss: 0.022222, Train Acc: 100.000000, Val Loss: 0.248724, Val Acc: 92.968750\n",
      "Epoch 19, Train Loss: 0.020845, Train Acc: 100.000000, Val Loss: 0.251353, Val Acc: 92.968750\n",
      "Epoch 20, Train Loss: 0.019567, Train Acc: 100.000000, Val Loss: 0.253781, Val Acc: 92.968750\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.550740, Train Acc: 70.392157, Val Loss: 1.730217, Val Acc: 59.375000\n",
      "Epoch 2, Train Loss: 0.198890, Train Acc: 91.764706, Val Loss: 0.342260, Val Acc: 86.718750\n",
      "Epoch 3, Train Loss: 0.175185, Train Acc: 92.941176, Val Loss: 0.226556, Val Acc: 89.843750\n",
      "Epoch 4, Train Loss: 0.144626, Train Acc: 95.098039, Val Loss: 0.276645, Val Acc: 88.281250\n",
      "Epoch 5, Train Loss: 0.110920, Train Acc: 96.274510, Val Loss: 0.359872, Val Acc: 89.843750\n",
      "Epoch 6, Train Loss: 0.096584, Train Acc: 96.470588, Val Loss: 0.390204, Val Acc: 89.843750\n",
      "Epoch 7, Train Loss: 0.087797, Train Acc: 96.862745, Val Loss: 0.365299, Val Acc: 91.406250\n",
      "Epoch 8, Train Loss: 0.076630, Train Acc: 97.450980, Val Loss: 0.314179, Val Acc: 92.968750\n",
      "Epoch 9, Train Loss: 0.065244, Train Acc: 97.647059, Val Loss: 0.262024, Val Acc: 92.187500\n",
      "Epoch 10, Train Loss: 0.056783, Train Acc: 98.039216, Val Loss: 0.237069, Val Acc: 92.187500\n",
      "Epoch 11, Train Loss: 0.053978, Train Acc: 98.039216, Val Loss: 0.220186, Val Acc: 92.187500\n",
      "Epoch 12, Train Loss: 0.050844, Train Acc: 98.627451, Val Loss: 0.211443, Val Acc: 91.406250\n",
      "Epoch 13, Train Loss: 0.047622, Train Acc: 98.627451, Val Loss: 0.207359, Val Acc: 92.187500\n",
      "Epoch 14, Train Loss: 0.044444, Train Acc: 98.823529, Val Loss: 0.205879, Val Acc: 92.187500\n",
      "Epoch 15, Train Loss: 0.041360, Train Acc: 99.215686, Val Loss: 0.206357, Val Acc: 92.187500\n",
      "Epoch 16, Train Loss: 0.038392, Train Acc: 99.411765, Val Loss: 0.208267, Val Acc: 91.406250\n",
      "Epoch 17, Train Loss: 0.035587, Train Acc: 99.607843, Val Loss: 0.211002, Val Acc: 91.406250\n",
      "Epoch 18, Train Loss: 0.033006, Train Acc: 99.607843, Val Loss: 0.213942, Val Acc: 91.406250\n",
      "Epoch 19, Train Loss: 0.030592, Train Acc: 99.607843, Val Loss: 0.216977, Val Acc: 91.406250\n",
      "Epoch 20, Train Loss: 0.028337, Train Acc: 99.607843, Val Loss: 0.219988, Val Acc: 91.406250\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.673904, Train Acc: 63.333333, Val Loss: 0.614415, Val Acc: 72.656250\n",
      "Epoch 2, Train Loss: 0.212062, Train Acc: 90.784314, Val Loss: 0.478390, Val Acc: 77.343750\n",
      "Epoch 3, Train Loss: 0.169569, Train Acc: 92.745098, Val Loss: 0.331450, Val Acc: 82.031250\n",
      "Epoch 4, Train Loss: 0.136763, Train Acc: 93.725490, Val Loss: 0.283308, Val Acc: 85.937500\n",
      "Epoch 5, Train Loss: 0.090997, Train Acc: 96.862745, Val Loss: 0.286541, Val Acc: 83.593750\n",
      "Epoch 6, Train Loss: 0.069901, Train Acc: 97.647059, Val Loss: 0.329893, Val Acc: 82.812500\n",
      "Epoch 7, Train Loss: 0.060032, Train Acc: 98.039216, Val Loss: 0.338504, Val Acc: 83.593750\n",
      "Epoch 8, Train Loss: 0.048655, Train Acc: 97.843137, Val Loss: 0.319505, Val Acc: 86.718750\n",
      "Epoch 9, Train Loss: 0.038146, Train Acc: 98.823529, Val Loss: 0.315964, Val Acc: 86.718750\n",
      "Epoch 10, Train Loss: 0.031894, Train Acc: 99.019608, Val Loss: 0.328045, Val Acc: 87.500000\n",
      "Epoch 11, Train Loss: 0.026984, Train Acc: 99.607843, Val Loss: 0.337008, Val Acc: 87.500000\n",
      "Epoch 12, Train Loss: 0.025138, Train Acc: 99.607843, Val Loss: 0.347553, Val Acc: 87.500000\n",
      "Epoch 13, Train Loss: 0.023114, Train Acc: 99.803922, Val Loss: 0.356021, Val Acc: 88.281250\n",
      "Epoch 14, Train Loss: 0.021164, Train Acc: 99.803922, Val Loss: 0.364623, Val Acc: 87.500000\n",
      "Epoch 15, Train Loss: 0.019446, Train Acc: 99.803922, Val Loss: 0.373890, Val Acc: 87.500000\n",
      "Epoch 16, Train Loss: 0.018006, Train Acc: 99.803922, Val Loss: 0.383389, Val Acc: 87.500000\n",
      "Epoch 17, Train Loss: 0.017009, Train Acc: 99.803922, Val Loss: 0.388476, Val Acc: 87.500000\n",
      "Epoch 18, Train Loss: 0.016663, Train Acc: 99.803922, Val Loss: 0.393268, Val Acc: 87.500000\n",
      "Epoch 19, Train Loss: 0.016311, Train Acc: 99.803922, Val Loss: 0.397641, Val Acc: 87.500000\n",
      "Epoch 20, Train Loss: 0.015955, Train Acc: 99.803922, Val Loss: 0.401482, Val Acc: 87.500000\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.717204, Train Acc: 65.686275, Val Loss: 0.291181, Val Acc: 86.718750\n",
      "Epoch 2, Train Loss: 0.238264, Train Acc: 89.607843, Val Loss: 0.241610, Val Acc: 93.750000\n",
      "Epoch 3, Train Loss: 0.196091, Train Acc: 92.352941, Val Loss: 0.352172, Val Acc: 82.812500\n",
      "Epoch 4, Train Loss: 0.177837, Train Acc: 92.941176, Val Loss: 0.367814, Val Acc: 84.375000\n",
      "Epoch 5, Train Loss: 0.140759, Train Acc: 94.313725, Val Loss: 0.249880, Val Acc: 90.625000\n",
      "Epoch 6, Train Loss: 0.109129, Train Acc: 95.686275, Val Loss: 0.199968, Val Acc: 94.531250\n",
      "Epoch 7, Train Loss: 0.092477, Train Acc: 96.862745, Val Loss: 0.206245, Val Acc: 93.750000\n",
      "Epoch 8, Train Loss: 0.087448, Train Acc: 96.862745, Val Loss: 0.203380, Val Acc: 93.750000\n",
      "Epoch 9, Train Loss: 0.079951, Train Acc: 97.058824, Val Loss: 0.198827, Val Acc: 92.187500\n",
      "Epoch 10, Train Loss: 0.068262, Train Acc: 97.254902, Val Loss: 0.206241, Val Acc: 92.968750\n",
      "Epoch 11, Train Loss: 0.058529, Train Acc: 98.235294, Val Loss: 0.217012, Val Acc: 93.750000\n",
      "Epoch 12, Train Loss: 0.051327, Train Acc: 98.627451, Val Loss: 0.224103, Val Acc: 93.750000\n",
      "Epoch 13, Train Loss: 0.044849, Train Acc: 98.823529, Val Loss: 0.230055, Val Acc: 92.187500\n",
      "Epoch 14, Train Loss: 0.039728, Train Acc: 99.019608, Val Loss: 0.239691, Val Acc: 92.187500\n",
      "Epoch 15, Train Loss: 0.036245, Train Acc: 99.215686, Val Loss: 0.252741, Val Acc: 92.187500\n",
      "Epoch 16, Train Loss: 0.033462, Train Acc: 99.411765, Val Loss: 0.260000, Val Acc: 92.187500\n",
      "Epoch 17, Train Loss: 0.032267, Train Acc: 99.607843, Val Loss: 0.267040, Val Acc: 91.406250\n",
      "Epoch 18, Train Loss: 0.030867, Train Acc: 99.607843, Val Loss: 0.273708, Val Acc: 90.625000\n",
      "Epoch 19, Train Loss: 0.029452, Train Acc: 99.607843, Val Loss: 0.279575, Val Acc: 90.625000\n",
      "Epoch 20, Train Loss: 0.028105, Train Acc: 99.803922, Val Loss: 0.284638, Val Acc: 90.625000\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.733395, Train Acc: 59.607843, Val Loss: 1.658996, Val Acc: 60.156250\n",
      "Epoch 2, Train Loss: 0.248384, Train Acc: 90.196078, Val Loss: 0.727952, Val Acc: 71.093750\n",
      "Epoch 3, Train Loss: 0.180927, Train Acc: 91.764706, Val Loss: 0.268845, Val Acc: 88.281250\n",
      "Epoch 4, Train Loss: 0.165648, Train Acc: 92.549020, Val Loss: 0.217341, Val Acc: 89.062500\n",
      "Epoch 5, Train Loss: 0.142355, Train Acc: 94.117647, Val Loss: 0.270542, Val Acc: 87.500000\n",
      "Epoch 6, Train Loss: 0.109043, Train Acc: 95.098039, Val Loss: 0.368224, Val Acc: 82.812500\n",
      "Epoch 7, Train Loss: 0.093850, Train Acc: 96.274510, Val Loss: 0.361830, Val Acc: 83.593750\n",
      "Epoch 8, Train Loss: 0.086655, Train Acc: 96.274510, Val Loss: 0.276514, Val Acc: 85.937500\n",
      "Epoch 9, Train Loss: 0.075672, Train Acc: 97.254902, Val Loss: 0.202085, Val Acc: 90.625000\n",
      "Epoch 10, Train Loss: 0.066456, Train Acc: 97.254902, Val Loss: 0.174961, Val Acc: 89.843750\n",
      "Epoch 11, Train Loss: 0.061091, Train Acc: 97.647059, Val Loss: 0.176987, Val Acc: 89.843750\n",
      "Epoch 12, Train Loss: 0.054679, Train Acc: 98.235294, Val Loss: 0.188415, Val Acc: 90.625000\n",
      "Epoch 13, Train Loss: 0.046519, Train Acc: 98.823529, Val Loss: 0.200343, Val Acc: 91.406250\n",
      "Epoch 14, Train Loss: 0.040005, Train Acc: 98.823529, Val Loss: 0.208636, Val Acc: 92.187500\n",
      "Epoch 15, Train Loss: 0.035186, Train Acc: 99.019608, Val Loss: 0.211261, Val Acc: 92.187500\n",
      "Epoch 16, Train Loss: 0.030659, Train Acc: 99.215686, Val Loss: 0.212690, Val Acc: 92.968750\n",
      "Epoch 17, Train Loss: 0.027001, Train Acc: 99.411765, Val Loss: 0.215782, Val Acc: 92.968750\n",
      "Epoch 18, Train Loss: 0.025792, Train Acc: 99.411765, Val Loss: 0.220075, Val Acc: 92.968750\n",
      "Epoch 19, Train Loss: 0.024534, Train Acc: 99.607843, Val Loss: 0.225279, Val Acc: 94.531250\n",
      "Epoch 20, Train Loss: 0.023319, Train Acc: 99.607843, Val Loss: 0.231007, Val Acc: 94.531250\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.636997, Train Acc: 62.156863, Val Loss: 1.105672, Val Acc: 63.281250\n",
      "Epoch 2, Train Loss: 0.237237, Train Acc: 89.019608, Val Loss: 0.419037, Val Acc: 78.125000\n",
      "Epoch 3, Train Loss: 0.179918, Train Acc: 93.333333, Val Loss: 0.243583, Val Acc: 89.062500\n",
      "Epoch 4, Train Loss: 0.150379, Train Acc: 93.921569, Val Loss: 0.243729, Val Acc: 89.843750\n",
      "Epoch 5, Train Loss: 0.118148, Train Acc: 95.294118, Val Loss: 0.333111, Val Acc: 89.062500\n",
      "Epoch 6, Train Loss: 0.103603, Train Acc: 96.274510, Val Loss: 0.403759, Val Acc: 87.500000\n",
      "Epoch 7, Train Loss: 0.090749, Train Acc: 96.666667, Val Loss: 0.354888, Val Acc: 88.281250\n",
      "Epoch 8, Train Loss: 0.074476, Train Acc: 97.450980, Val Loss: 0.268720, Val Acc: 92.187500\n",
      "Epoch 9, Train Loss: 0.062413, Train Acc: 97.647059, Val Loss: 0.219227, Val Acc: 93.750000\n",
      "Epoch 10, Train Loss: 0.055956, Train Acc: 98.039216, Val Loss: 0.210841, Val Acc: 92.968750\n",
      "Epoch 11, Train Loss: 0.049285, Train Acc: 98.235294, Val Loss: 0.224344, Val Acc: 92.187500\n",
      "Epoch 12, Train Loss: 0.040790, Train Acc: 98.823529, Val Loss: 0.246065, Val Acc: 92.968750\n",
      "Epoch 13, Train Loss: 0.034115, Train Acc: 99.019608, Val Loss: 0.271535, Val Acc: 92.968750\n",
      "Epoch 14, Train Loss: 0.029912, Train Acc: 99.607843, Val Loss: 0.293252, Val Acc: 92.968750\n",
      "Epoch 15, Train Loss: 0.026099, Train Acc: 100.000000, Val Loss: 0.307309, Val Acc: 92.968750\n",
      "Epoch 16, Train Loss: 0.021903, Train Acc: 100.000000, Val Loss: 0.318646, Val Acc: 92.187500\n",
      "Epoch 17, Train Loss: 0.019044, Train Acc: 100.000000, Val Loss: 0.326186, Val Acc: 92.187500\n",
      "Epoch 18, Train Loss: 0.018092, Train Acc: 100.000000, Val Loss: 0.333503, Val Acc: 92.187500\n",
      "Epoch 19, Train Loss: 0.017140, Train Acc: 100.000000, Val Loss: 0.340617, Val Acc: 92.187500\n",
      "Epoch 20, Train Loss: 0.016190, Train Acc: 100.000000, Val Loss: 0.347534, Val Acc: 92.187500\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.656854, Train Acc: 59.607843, Val Loss: 0.992782, Val Acc: 64.843750\n",
      "Epoch 2, Train Loss: 0.230004, Train Acc: 90.588235, Val Loss: 0.374528, Val Acc: 83.593750\n",
      "Epoch 3, Train Loss: 0.171754, Train Acc: 94.509804, Val Loss: 0.255633, Val Acc: 87.500000\n",
      "Epoch 4, Train Loss: 0.145826, Train Acc: 94.313725, Val Loss: 0.241593, Val Acc: 87.500000\n",
      "Epoch 5, Train Loss: 0.107525, Train Acc: 95.490196, Val Loss: 0.415513, Val Acc: 84.375000\n",
      "Epoch 6, Train Loss: 0.085390, Train Acc: 96.470588, Val Loss: 0.613621, Val Acc: 80.468750\n",
      "Epoch 7, Train Loss: 0.075713, Train Acc: 97.058824, Val Loss: 0.622254, Val Acc: 80.468750\n",
      "Epoch 8, Train Loss: 0.063418, Train Acc: 97.647059, Val Loss: 0.509850, Val Acc: 85.156250\n",
      "Epoch 9, Train Loss: 0.051945, Train Acc: 98.627451, Val Loss: 0.414822, Val Acc: 88.281250\n",
      "Epoch 10, Train Loss: 0.045814, Train Acc: 98.235294, Val Loss: 0.378819, Val Acc: 89.062500\n",
      "Epoch 11, Train Loss: 0.039690, Train Acc: 98.235294, Val Loss: 0.370299, Val Acc: 89.062500\n",
      "Epoch 12, Train Loss: 0.036585, Train Acc: 99.019608, Val Loss: 0.375998, Val Acc: 88.281250\n",
      "Epoch 13, Train Loss: 0.033203, Train Acc: 99.411765, Val Loss: 0.390833, Val Acc: 87.500000\n",
      "Epoch 14, Train Loss: 0.030252, Train Acc: 99.803922, Val Loss: 0.408338, Val Acc: 89.062500\n",
      "Epoch 15, Train Loss: 0.027967, Train Acc: 99.803922, Val Loss: 0.425828, Val Acc: 89.062500\n",
      "Epoch 16, Train Loss: 0.026222, Train Acc: 99.803922, Val Loss: 0.441379, Val Acc: 89.062500\n",
      "Epoch 17, Train Loss: 0.025022, Train Acc: 99.803922, Val Loss: 0.450793, Val Acc: 89.062500\n",
      "Epoch 18, Train Loss: 0.024562, Train Acc: 99.803922, Val Loss: 0.459203, Val Acc: 89.062500\n",
      "Epoch 19, Train Loss: 0.024049, Train Acc: 99.803922, Val Loss: 0.466473, Val Acc: 87.500000\n",
      "Epoch 20, Train Loss: 0.023503, Train Acc: 99.803922, Val Loss: 0.472711, Val Acc: 87.500000\n",
      "Model:Baseline_MLP\n",
      "Epoch 1, Train Loss: 0.782826, Train Acc: 54.901961, Val Loss: 0.907622, Val Acc: 64.843750\n",
      "Epoch 2, Train Loss: 0.256074, Train Acc: 89.215686, Val Loss: 0.251092, Val Acc: 87.500000\n",
      "Epoch 3, Train Loss: 0.193704, Train Acc: 91.764706, Val Loss: 0.239455, Val Acc: 89.062500\n",
      "Epoch 4, Train Loss: 0.165490, Train Acc: 92.941176, Val Loss: 0.157745, Val Acc: 93.750000\n",
      "Epoch 5, Train Loss: 0.121006, Train Acc: 94.705882, Val Loss: 0.176287, Val Acc: 89.062500\n",
      "Epoch 6, Train Loss: 0.103751, Train Acc: 95.686275, Val Loss: 0.189383, Val Acc: 89.843750\n",
      "Epoch 7, Train Loss: 0.092849, Train Acc: 95.686275, Val Loss: 0.151305, Val Acc: 92.187500\n",
      "Epoch 8, Train Loss: 0.078128, Train Acc: 96.862745, Val Loss: 0.135083, Val Acc: 92.968750\n",
      "Epoch 9, Train Loss: 0.068500, Train Acc: 97.647059, Val Loss: 0.144825, Val Acc: 92.968750\n",
      "Epoch 10, Train Loss: 0.061387, Train Acc: 97.843137, Val Loss: 0.148546, Val Acc: 92.968750\n",
      "Epoch 11, Train Loss: 0.053337, Train Acc: 98.627451, Val Loss: 0.148013, Val Acc: 92.187500\n",
      "Epoch 12, Train Loss: 0.045411, Train Acc: 98.431373, Val Loss: 0.153453, Val Acc: 92.187500\n",
      "Epoch 13, Train Loss: 0.038494, Train Acc: 99.019608, Val Loss: 0.166219, Val Acc: 91.406250\n",
      "Epoch 14, Train Loss: 0.032904, Train Acc: 99.411765, Val Loss: 0.181431, Val Acc: 89.843750\n",
      "Epoch 15, Train Loss: 0.028603, Train Acc: 99.803922, Val Loss: 0.189302, Val Acc: 89.843750\n",
      "Epoch 16, Train Loss: 0.027038, Train Acc: 99.803922, Val Loss: 0.197252, Val Acc: 89.843750\n",
      "Epoch 17, Train Loss: 0.025487, Train Acc: 99.803922, Val Loss: 0.205647, Val Acc: 90.625000\n",
      "Epoch 18, Train Loss: 0.024068, Train Acc: 100.000000, Val Loss: 0.213885, Val Acc: 90.625000\n",
      "Epoch 19, Train Loss: 0.022768, Train Acc: 100.000000, Val Loss: 0.220535, Val Acc: 90.625000\n",
      "Epoch 20, Train Loss: 0.021510, Train Acc: 100.000000, Val Loss: 0.225919, Val Acc: 90.625000\n",
      "Finished! \n",
      " Acc:(91.09375, 94.53125), \n",
      " list:[89.84375, 93.75, 92.96875, 91.40625, 87.5, 90.625, 94.53125, 92.1875, 87.5, 90.625]\n"
     ]
    }
   ],
   "source": [
    "# 集成版本\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import json\n",
    "from data.data_loader import load_and_align_data, create_data_loader\n",
    "from models.model import *\n",
    "from utils import *  # 假设你有评估和早停的辅助函数\n",
    "from torch_geometric.data import Data          \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "#from config import config\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 设置训练设备\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 结果的接收器\n",
    "random.seed(99)\n",
    "result = []\n",
    "repeat_times = config['train']['repeat_times']\n",
    "random_state = config['data']['random_state']\n",
    "\n",
    "if repeat_times != 1:\n",
    "    random_state = [random.randint(0, 10000) for _ in range(config['train']['repeat_times'])]\n",
    "    print(f'共分割样本{repeat_times}次，随机数种子为：{random_state}')\n",
    "elif repeat_times == 1:\n",
    "    random_state = [config['data']['random_state']]\n",
    "    print(f'仅进行{repeat_times}次分割样本，随机数种子为：{random_state}')\n",
    "    \n",
    "brain_adj_matrix = read_brain_region_adjacency(config[\"data\"][\"brain_region_adjacency_path\"])\n",
    "brain_edge_index,_ = dense_to_sparse(brain_adj_matrix)\n",
    "\n",
    "for seed in random_state:\n",
    "    # 加载数据并创建数据集\n",
    "    train_dataset, val_dataset, _ = load_and_align_data(high_dim_path = config['data']['high_dim_path'], \n",
    "                                                      low_dim_path = config['data']['low_dim_path'],\n",
    "                                                      labels_path = config['data']['labels_path'],\n",
    "                                                      test_size = config['data']['test_size'],\n",
    "                                                      val_size = config['data']['val_size'],\n",
    "                                                      random_state = seed)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = create_data_loader(train_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    val_loader = create_data_loader(val_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    \n",
    "    if config['model']['type'] == 'CombinedGAT':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = CombinedGAT(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"],\n",
    "                     num_heads=config[\"model\"][\"num_heads\"]).to(device)\n",
    "    elif config['model']['type'] == 'Baseline_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Baseline_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'high_low_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = high_low_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'only_high_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = only_high_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'only_low_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = only_high_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'Only_high_GCN':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Only_high_GCN(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'test_high':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = test_high(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'test_high_correlation':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = test_high_correlation(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'BrainGNN':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = BrainGNN(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"],\n",
    "                     num_features=config[\"model\"][\"num_features\"]\n",
    "                        ).to(device)\n",
    "    else:\n",
    "        print(f\"Not found Model:{config['model']['type']}\")\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['train']['learning_rate'])\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=5)\n",
    "    \n",
    "    # 初始化早停对象\n",
    "    early_stopping = EarlyStopping(patience=config[\"earlystopping\"][\"patience\"], delta=config[\"earlystopping\"][\"delta\"])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config['train']['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for high_dim_features, low_dim_features, labels in train_loader: \n",
    "            batch_size = high_dim_features.size(0)  # 获取当前批次的大小\n",
    "            \n",
    "            # 为当前批次生成全连接的邻接矩阵\n",
    "            if config[\"model\"][\"way_adjmatrix\"] == 'zero':\n",
    "                adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'only_three':\n",
    "                adj_matrix = build_adj_matrix_only_three(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'similarity_add_three':\n",
    "                adj_matrix = build_adj_matrix_similarity_add_three(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'sex':\n",
    "                adj_matrix = build_adj_matrix_sex(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'apoe':\n",
    "                adj_matrix = build_adj_matrix_apoe(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'mmse':\n",
    "                adj_matrix = build_adj_matrix_mmse(high_dim_features,low_dim_features,sigma=1)\n",
    "            edge_index, _ = dense_to_sparse(adj_matrix)\n",
    "            \n",
    "            # 准备数据\n",
    "            high_dim_features = high_dim_features.to(device)\n",
    "            low_dim_features = low_dim_features.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            high_dim_cov_matrix = cov_builder(high_dim_features , labels).to(device)\n",
    "\n",
    "            brain_edge_index = brain_edge_index.to(device)\n",
    "    \n",
    "            # 前向传播\n",
    "            outputs = model(high_dim_features, low_dim_features, brain_edge_index)#, high_dim_cov_matrix) #edge_index, high_dim_cov_matrix)\n",
    "            # outputs = model(high_dim_features, low_dim_features, edge_index, high_dim_cov_matrix)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "    \n",
    "        # 计算验证集上的损失\n",
    "        model.eval()\n",
    "        val_total_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_acc_list = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for high_dim_features, low_dim_features, labels in val_loader: \n",
    "                batch_size = high_dim_features.size(0)  # 获取当前批次的大小\n",
    "                \n",
    "                # 为当前批次生成全连接的邻接矩阵\n",
    "                if config[\"model\"][\"way_adjmatrix\"] == 'zero':\n",
    "                    adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'only_three':\n",
    "                    adj_matrix = build_adj_matrix_only_three(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'similarity_add_three':\n",
    "                    adj_matrix = build_adj_matrix_similarity_add_three(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'sex':\n",
    "                    adj_matrix = build_adj_matrix_sex(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'apoe':\n",
    "                    adj_matrix = build_adj_matrix_apoe(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'mmse':\n",
    "                    adj_matrix = build_adj_matrix_mmse(high_dim_features,low_dim_features,sigma=1)\n",
    "                edge_index, _ = dense_to_sparse(adj_matrix)\n",
    "                    \n",
    "                high_dim_features = high_dim_features.to(device)\n",
    "                low_dim_features = low_dim_features.float().to(device)\n",
    "                labels = labels.to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                \n",
    "                high_dim_cov_matrix = cov_builder(high_dim_features , labels).to(device)\n",
    "                \n",
    "                outputs = model(high_dim_features, low_dim_features, brain_edge_index)#,high_dim_cov_matrix)\n",
    "                #outputs = model(high_dim_features, low_dim_features, edge_index,high_dim_cov_matrix)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        val_loss =  val_total_loss/len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        scheduler.step(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.6f}, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.6f}')\n",
    "        # print(f'Wrong_sample:{val_total-val_correct},Index:{[index for index, (item1, item2) in enumerate(zip(predicted, labels)) if item1 != item2]}')\n",
    "        # print(predicted)\n",
    "        \n",
    "        if config[\"earlystopping\"][\"is_on\"]:\n",
    "            early_stopping(val_loss,model)\n",
    "            if  early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    predicted_list = predicted_list + predicted.tolist()\n",
    "    labels_list = labels_list + labels.tolist()\n",
    "                \n",
    "    result.append(max(val_acc_list))\n",
    "print(f'Finished! \\n Acc:{np.mean(result),max(result)}, \\n list:{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de764376-ebee-49e0-9b15-f53514de9345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9109375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_list) #2000\n",
    "predicted_list.count(0)\n",
    "predicted_list.count(1)\n",
    "labels_list.count(0)\n",
    "sum([1 for label, predicted in zip(labels_list, predicted_list) if label == predicted])/len(predicted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b65c958-50d7-4ae1-a07a-13848a8fc937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[534.,  56.],\n",
       "        [ 58., 632.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = torch.tensor(predicted_list)\n",
    "labels = torch.tensor(labels_list)\n",
    "\n",
    "# 确定类别总数\n",
    "num_classes = torch.max(torch.cat((predicted, labels))) + 1\n",
    "\n",
    "# 初始化混淆矩阵\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "# 填充混淆矩阵\n",
    "for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a753efe4-b56d-4261-ace3-8769f43466a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9109\n",
      "Precision per class: 0.9051\n",
      "Recall per class: 0.9020\n",
      "F1 Score per class: 0.9036\n"
     ]
    }
   ],
   "source": [
    "# 计算性能指标\n",
    "TP = int(confusion_matrix[0][0])\n",
    "FP = int(confusion_matrix[0][1])\n",
    "FN = int(confusion_matrix[1][0])\n",
    "TN = int(confusion_matrix[1][1])\n",
    "\n",
    "# 精确率 Precision\n",
    "precision = TP / (TP + FP)\n",
    "# 召回率 Recall\n",
    "recall = TP / (TP + FN)\n",
    "# F1分数\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# 计算总体准确率\n",
    "accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision per class: {precision:.4f}')\n",
    "print(f'Recall per class: {recall:.4f}')\n",
    "print(f'F1 Score per class: {F1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d52a0c-aee6-4e2b-9a06-4fb1fa97fa75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
