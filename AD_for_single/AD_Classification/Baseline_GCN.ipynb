{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280c992a-7740-4243-905e-f62ea1d2234a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361eec62-ac69-43e5-bfe2-55284afe7502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "config = {\n",
    "  \"data\": {\n",
    "    \"high_dim_path\": 'data/PET.csv',\n",
    "    \"low_dim_path\": 'data/ALL.csv',\n",
    "    \"labels_path\": 'data/LABEL.csv',\n",
    "    \"brain_region_adjacency_path\" : 'data/region_adjacency.csv',\n",
    "    \"batch_size\": 256,\n",
    "    \"shuffle\": False,\n",
    "    \"test_size\":0.01,\n",
    "    \"val_size\":0.2,\n",
    "    \"random_state\":12345\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"type\": \"Baseline_GCN\", # 设置模型跑哪个\n",
    "    \"way_adjmatrix\" : \"similarity_add_three\", # 邻接矩阵如何构造\n",
    "    \"high_dim_input_size\": 166  ,  \n",
    "    \"low_dim_input_size\":17,\n",
    "    \"embedding_dim\":128,\n",
    "    \"output_dim\":2,\n",
    "    \"hidden_channels\":128,\n",
    "    \"num_heads\":4 ,\n",
    "    \"num_features\":1 # 每个脑区的特征数\n",
    "      \n",
    "  },\n",
    "  \"train\": {\n",
    "    \"repeat_times\" :1, # 简单完成交叉验证的任务\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"device\": \"cuda:1\"\n",
    "  },\n",
    "  \"earlystopping\":{\n",
    "    \"is_on\":False,\n",
    "    \"patience\":5,\n",
    "    \"delta\":0.01\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60bfbaed-866e-460e-acd2-97fea58bff91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "仅进行1次分割样本，随机数种子为：[12345]\n",
      "Model:Baseline_GCN\n",
      "Epoch 1, Train Loss: 1.770549, Train Acc: 51.519337, Val Loss: 2.785772, Val Acc: 48.066298\n",
      "Epoch 2, Train Loss: 1.237100, Train Acc: 58.287293, Val Loss: 1.289500, Val Acc: 51.933702\n",
      "Epoch 3, Train Loss: 0.842966, Train Acc: 55.110497, Val Loss: 0.830785, Val Acc: 50.276243\n",
      "Epoch 4, Train Loss: 0.703573, Train Acc: 65.745856, Val Loss: 0.819229, Val Acc: 56.906077\n",
      "Epoch 5, Train Loss: 0.615718, Train Acc: 71.408840, Val Loss: 0.699151, Val Acc: 61.878453\n",
      "Epoch 6, Train Loss: 0.592786, Train Acc: 69.613260, Val Loss: 0.709711, Val Acc: 62.430939\n",
      "Epoch 7, Train Loss: 0.601785, Train Acc: 68.646409, Val Loss: 0.652773, Val Acc: 66.298343\n",
      "Epoch 8, Train Loss: 0.559925, Train Acc: 73.342541, Val Loss: 0.756399, Val Acc: 65.745856\n",
      "Epoch 9, Train Loss: 0.508424, Train Acc: 74.723757, Val Loss: 0.594186, Val Acc: 72.928177\n",
      "Epoch 10, Train Loss: 0.503524, Train Acc: 74.033149, Val Loss: 0.643647, Val Acc: 67.403315\n",
      "Epoch 11, Train Loss: 0.484837, Train Acc: 76.243094, Val Loss: 0.681054, Val Acc: 67.403315\n",
      "Epoch 12, Train Loss: 0.477560, Train Acc: 74.861878, Val Loss: 0.598439, Val Acc: 70.718232\n",
      "Epoch 13, Train Loss: 0.474861, Train Acc: 76.104972, Val Loss: 0.687469, Val Acc: 68.508287\n",
      "Epoch 14, Train Loss: 0.446487, Train Acc: 77.348066, Val Loss: 0.688289, Val Acc: 70.165746\n",
      "Epoch 15, Train Loss: 0.429003, Train Acc: 77.900552, Val Loss: 0.697063, Val Acc: 65.745856\n",
      "Epoch 16, Train Loss: 0.420213, Train Acc: 78.038674, Val Loss: 0.653470, Val Acc: 68.508287\n",
      "Epoch 17, Train Loss: 0.407776, Train Acc: 80.662983, Val Loss: 0.704683, Val Acc: 67.955801\n",
      "Epoch 18, Train Loss: 0.396490, Train Acc: 81.077348, Val Loss: 0.717866, Val Acc: 67.403315\n",
      "Epoch 19, Train Loss: 0.392220, Train Acc: 81.215470, Val Loss: 0.680877, Val Acc: 64.640884\n",
      "Epoch 20, Train Loss: 0.402726, Train Acc: 81.215470, Val Loss: 0.692128, Val Acc: 70.165746\n",
      "Finished! \n",
      " Acc:(70.1657458563536, 70.1657458563536), \n",
      " list:[70.1657458563536]\n"
     ]
    }
   ],
   "source": [
    "# 集成版本\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import json\n",
    "from data.data_loader import load_and_align_data, create_data_loader\n",
    "from models.model import *\n",
    "from utils import *  # 假设你有评估和早停的辅助函数\n",
    "from torch_geometric.data import Data          \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "#from config import config\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 设置训练设备\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 结果的接收器\n",
    "random.seed(99)\n",
    "result = []\n",
    "repeat_times = config['train']['repeat_times']\n",
    "random_state = config['data']['random_state']\n",
    "\n",
    "if repeat_times != 1:\n",
    "    random_state = [random.randint(0, 10000) for _ in range(config['train']['repeat_times'])]\n",
    "    print(f'共分割样本{repeat_times}次，随机数种子为：{random_state}')\n",
    "elif repeat_times == 1:\n",
    "    random_state = [config['data']['random_state']]\n",
    "    print(f'仅进行{repeat_times}次分割样本，随机数种子为：{random_state}')\n",
    "    \n",
    "brain_adj_matrix = read_brain_region_adjacency(config[\"data\"][\"brain_region_adjacency_path\"])\n",
    "brain_edge_index,_ = dense_to_sparse(brain_adj_matrix)\n",
    "\n",
    "for seed in random_state:\n",
    "    # 加载数据并创建数据集\n",
    "    train_dataset, val_dataset, _ = load_and_align_data(high_dim_path = config['data']['high_dim_path'], \n",
    "                                                      low_dim_path = config['data']['low_dim_path'],\n",
    "                                                      labels_path = config['data']['labels_path'],\n",
    "                                                      test_size = config['data']['test_size'],\n",
    "                                                      val_size = config['data']['val_size'],\n",
    "                                                      random_state = seed)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = create_data_loader(train_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    val_loader = create_data_loader(val_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    \n",
    "    if config['model']['type'] == 'Baseline_GCN':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Baseline_GCN(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'Baseline_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Baseline_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'high_low_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = high_low_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'only_high_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = only_high_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'only_low_MLP':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = only_high_MLP(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'Only_high_GCN':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = Only_high_GCN(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'test_high':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = test_high(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'test_high_correlation':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = test_high_correlation(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "    elif config['model']['type'] == 'BrainGNN':\n",
    "        print(f\"Model:{config['model']['type']}\")\n",
    "        model = BrainGNN(high_dim_input_size=config[\"model\"][\"high_dim_input_size\"],  # 适当调整这些参数，这里可以写成config\n",
    "                     low_dim_input_size=config[\"model\"][\"low_dim_input_size\"],\n",
    "                     embedding_dim=config[\"model\"][\"embedding_dim\"],\n",
    "                     output_dim=config[\"model\"][\"output_dim\"],  # 根据您的任务调整\n",
    "                     hidden_channels=config[\"model\"][\"hidden_channels\"],\n",
    "                     num_features=config[\"model\"][\"num_features\"]\n",
    "                        ).to(device)\n",
    "    else:\n",
    "        print(f\"Not found Model:{config['model']['type']}\")\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['train']['learning_rate'])\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=5)\n",
    "    \n",
    "    # 初始化早停对象\n",
    "    early_stopping = EarlyStopping(patience=config[\"earlystopping\"][\"patience\"], delta=config[\"earlystopping\"][\"delta\"])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config['train']['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for high_dim_features, low_dim_features, labels in train_loader: \n",
    "            batch_size = high_dim_features.size(0)  # 获取当前批次的大小\n",
    "            \n",
    "            # 为当前批次生成全连接的邻接矩阵\n",
    "            if config[\"model\"][\"way_adjmatrix\"] == 'zero':\n",
    "                adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'only_three':\n",
    "                adj_matrix = build_adj_matrix_only_three(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'similarity_add_three':\n",
    "                adj_matrix = build_adj_matrix_similarity_add_three(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'sex':\n",
    "                adj_matrix = build_adj_matrix_sex(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'apoe':\n",
    "                adj_matrix = build_adj_matrix_apoe(high_dim_features,low_dim_features,sigma=1)\n",
    "            elif config[\"model\"][\"way_adjmatrix\"] == 'mmse':\n",
    "                adj_matrix = build_adj_matrix_mmse(high_dim_features,low_dim_features,sigma=1)\n",
    "            edge_index, _ = dense_to_sparse(adj_matrix)\n",
    "            \n",
    "            # 准备数据\n",
    "            high_dim_features = high_dim_features.to(device)\n",
    "            low_dim_features = low_dim_features.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            high_dim_cov_matrix = cov_builder_PET(high_dim_features , labels).to(device)\n",
    "\n",
    "            brain_edge_index = brain_edge_index.to(device)\n",
    "    \n",
    "            # 前向传播\n",
    "            outputs = model(high_dim_features, low_dim_features, edge_index)#, high_dim_cov_matrix) #edge_index, high_dim_cov_matrix)\n",
    "            # outputs = model(high_dim_features, low_dim_features, edge_index, high_dim_cov_matrix)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "    \n",
    "        # 计算验证集上的损失\n",
    "        model.eval()\n",
    "        val_total_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_acc_list = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for high_dim_features, low_dim_features, labels in val_loader: \n",
    "                batch_size = high_dim_features.size(0)  # 获取当前批次的大小\n",
    "                \n",
    "                # 为当前批次生成全连接的邻接矩阵\n",
    "                if config[\"model\"][\"way_adjmatrix\"] == 'zero':\n",
    "                    adj_matrix = torch.zeros((batch_size, batch_size))\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'only_three':\n",
    "                    adj_matrix = build_adj_matrix_only_three(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'similarity_add_three':\n",
    "                    adj_matrix = build_adj_matrix_similarity_add_three(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'sex':\n",
    "                    adj_matrix = build_adj_matrix_sex(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'apoe':\n",
    "                    adj_matrix = build_adj_matrix_apoe(high_dim_features,low_dim_features,sigma=1)\n",
    "                elif config[\"model\"][\"way_adjmatrix\"] == 'mmse':\n",
    "                    adj_matrix = build_adj_matrix_mmse(high_dim_features,low_dim_features,sigma=1)\n",
    "                edge_index, _ = dense_to_sparse(adj_matrix)\n",
    "                    \n",
    "                high_dim_features = high_dim_features.to(device)\n",
    "                low_dim_features = low_dim_features.float().to(device)\n",
    "                labels = labels.to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                \n",
    "                high_dim_cov_matrix = cov_builder_PET(high_dim_features , labels).to(device)\n",
    "                \n",
    "                outputs = model(high_dim_features, low_dim_features, edge_index)#,high_dim_cov_matrix)\n",
    "                #outputs = model(high_dim_features, low_dim_features, edge_index,high_dim_cov_matrix)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        val_loss =  val_total_loss/len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        scheduler.step(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.6f}, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.6f}')\n",
    "        # print(f'Wrong_sample:{val_total-val_correct},Index:{[index for index, (item1, item2) in enumerate(zip(predicted, labels)) if item1 != item2]}')\n",
    "        # print(predicted)\n",
    "        \n",
    "        if config[\"earlystopping\"][\"is_on\"]:\n",
    "            early_stopping(val_loss,model)\n",
    "            if  early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    predicted_list = predicted_list + predicted.tolist()\n",
    "    labels_list = labels_list + labels.tolist()\n",
    "                \n",
    "    result.append(max(val_acc_list))\n",
    "print(f'Finished! \\n Acc:{np.mean(result),max(result)}, \\n list:{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de764376-ebee-49e0-9b15-f53514de9345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7016574585635359"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_list) #2000\n",
    "predicted_list.count(0)\n",
    "predicted_list.count(1)\n",
    "labels_list.count(0)\n",
    "sum([1 for label, predicted in zip(labels_list, predicted_list) if label == predicted])/len(predicted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b65c958-50d7-4ae1-a07a-13848a8fc937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[68., 26.],\n",
       "        [28., 59.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = torch.tensor(predicted_list)\n",
    "labels = torch.tensor(labels_list)\n",
    "\n",
    "# 确定类别总数\n",
    "num_classes = torch.max(torch.cat((predicted, labels))) + 1\n",
    "\n",
    "# 初始化混淆矩阵\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "# 填充混淆矩阵\n",
    "for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a753efe4-b56d-4261-ace3-8769f43466a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7017\n",
      "Precision per class: 0.7234\n",
      "Recall per class: 0.7083\n",
      "F1 Score per class: 0.7158\n"
     ]
    }
   ],
   "source": [
    "# 计算性能指标\n",
    "TP = int(confusion_matrix[0][0])\n",
    "FP = int(confusion_matrix[0][1])\n",
    "FN = int(confusion_matrix[1][0])\n",
    "TN = int(confusion_matrix[1][1])\n",
    "\n",
    "# 精确率 Precision\n",
    "precision = TP / (TP + FP)\n",
    "# 召回率 Recall\n",
    "recall = TP / (TP + FN)\n",
    "# F1分数\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# 计算总体准确率\n",
    "accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision per class: {precision:.4f}')\n",
    "print(f'Recall per class: {recall:.4f}')\n",
    "print(f'F1 Score per class: {F1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d52a0c-aee6-4e2b-9a06-4fb1fa97fa75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
