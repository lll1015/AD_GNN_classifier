{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b02f462-e0ab-45b8-ba5d-c454fb1f8444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/AD_for_fusion'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ba7ad5-d472-4159-9c24-c412c2e531a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"data\": {\n",
    "    \"PET_path\": \"data/PET.csv\",\n",
    "    \"MRI_path\": \"data/MRI_0328.csv\",\n",
    "    \"low_dim_path\": \"data/ALL.csv\",\n",
    "    \"labels_path\": \"data/LABEL.csv\",\n",
    "    \"batch_size\": 128,\n",
    "    \"shuffle\": False,\n",
    "    \"test_size\":0.2,\n",
    "    \"val_size\":0.1,\n",
    "    \"random_state\":42\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"type\": \"GCN\",\n",
    "    \"pet_input_size\": 166,  \n",
    "    \"mri_input_size\": 498,  \n",
    "    \"low_dim_input_size\":17,\n",
    "    \"embedding_dim\":64,\n",
    "    \"output_dim\":2,\n",
    "    \"hidden_channels\":128,\n",
    "    \"num_heads\":8 \n",
    "  },\n",
    "  \"train\": {\n",
    "    \"repeat_times\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"device\": \"cuda:1\"\n",
    "  },\n",
    "  \"earlystopping\":{\n",
    "    \"patience\":5,\n",
    "    \"delta\":0.001\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab451a06-5d24-40d8-bbee-158e2ef3aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集成版本\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import json\n",
    "from data.data_loader import load_and_align_data, create_data_loader\n",
    "from models.model import *\n",
    "from utils import * \n",
    "from torch_geometric.data import Data          \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "#from config import config\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 设置训练设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# 结果的接收器\n",
    "random.seed(99)\n",
    "result = []\n",
    "repeat_times = config['train']['repeat_times']\n",
    "random_state = config['data']['random_state']\n",
    "\n",
    "if repeat_times != 1:\n",
    "    random_state = [random.randint(0, 10000) for _ in range(config['train']['repeat_times'])]\n",
    "    print(f'共分割样本{repeat_times}次，随机数种子为：{random_state}')\n",
    "elif repeat_times == 1:\n",
    "    random_state = [config['data']['random_state']]\n",
    "    print(f'仅进行{repeat_times}次分割样本，随机数种子为：{random_state}')\n",
    "\n",
    "for seed in random_state:\n",
    "    # 加载数据并创建数据集\n",
    "    train_dataset, val_dataset, _ = load_and_align_data(PET_path = config['data']['PET_path'], \n",
    "                                                        MRI_path = config['data']['MRI_path'], \n",
    "                                                        low_dim_path = config['data']['low_dim_path'],\n",
    "                                                        labels_path = config['data']['labels_path'],\n",
    "                                                        test_size = config['data']['test_size'],\n",
    "                                                        val_size = config['data']['val_size'],\n",
    "                                                        random_state = seed)\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_loader = create_data_loader(train_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    val_loader = create_data_loader(val_dataset, batch_size=config['data']['batch_size'], shuffle=config['data']['shuffle'])\n",
    "    \n",
    "    \n",
    "    model = Fusion_model(pet_input_size = config[\"model\"][\"pet_input_size\"], \n",
    "                         mri_input_size = config[\"model\"][\"mri_input_size\"], \n",
    "                         low_dim_input_size = config[\"model\"][\"low_dim_input_size\"],\n",
    "                         embedding_dim = config[\"model\"][\"embedding_dim\"],\n",
    "                         output_dim = config[\"model\"][\"output_dim\"], \n",
    "                         hidden_channels = config[\"model\"][\"hidden_channels\"]).to(device)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['train']['learning_rate'])\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=5)\n",
    "    \n",
    "    # 初始化早停对象\n",
    "    early_stopping = EarlyStopping(patience=config[\"earlystopping\"][\"patience\"], delta=config[\"earlystopping\"][\"delta\"])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config['train']['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for pet_features, mri_features, low_dim_features, labels ,types in train_loader: \n",
    "            batch_size = pet_features.size(0)  # 获取当前批次的大小\n",
    "            # 准备数据\n",
    "            pet_features = pet_features.to(device)\n",
    "            mri_features = mri_features.to(device)\n",
    "            low_dim_features = low_dim_features.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            types = types.to(device)\n",
    "            \n",
    "#            if types == 1:\n",
    "#                for param in model.pet_branch.parameters():\n",
    "#                    param.requires_grad = False\n",
    "#            elif types == 2:\n",
    "#                for param in model.mri_branch.parameters():\n",
    "#                    param.requires_grad = False\n",
    "#            else: \n",
    "#                for param in model.parameters():\n",
    "#                    param.requires_grad = True\n",
    "        \n",
    "            optimizer.zero_grad()  # 清除梯度\n",
    "            outputs = model(pet_features, mri_features, low_dim_features,types)  # 前向传播\n",
    "            loss = criterion(outputs, labels)  # 计算损失\n",
    "            loss.backward()  # 反向传播\n",
    "        \n",
    "            # 仅更新需要更新的参数\n",
    "            optimizer.step()\n",
    "\n",
    "            # 将所有参数的梯度重新打开，为下一个batch准备\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "    \n",
    "        # 计算验证集上的损失\n",
    "        model.eval()\n",
    "        val_total_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_acc_list = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for pet_features, mri_features, low_dim_features, labels ,types in val_loader: \n",
    "                batch_size = pet_features.size(0)  # 获取当前批次的大小\n",
    "                    \n",
    "                # 准备数据\n",
    "                pet_features = pet_features.to(device)\n",
    "                mri_features = mri_features.to(device)\n",
    "                low_dim_features = low_dim_features.float().to(device)\n",
    "                labels = labels.to(device)\n",
    "                types = types.to(device)\n",
    "                \n",
    "                # high_dim_cov_matrix = cov_builder(high_dim_features , labels).to(device)\n",
    "                \n",
    "                outputs = model(pet_features, mri_features, low_dim_features,types)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        val_loss =  val_total_loss/len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        scheduler.step(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.6f}, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.6f}')\n",
    "                \n",
    "    result.append(max(val_acc_list))\n",
    "print(f'Finished! \\n Acc:{np.mean(result),max(result)}, \\n list:{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb01f5-706e-41c1-bf99-98ae4e2ad0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
